{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e5358657-3091-4dbe-90b4-27a439906f63",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.databricks.v1+bamboolib_hint": "{\"pd.DataFrames\": [], \"version\": \"0.0.1\"}",
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "from pyspark.ml.feature import StringIndexer, BucketedRandomProjectionLSH, VectorAssembler, StandardScaler, MinMaxScaler, Imputer\n",
    "from pyspark.ml.linalg import VectorUDT, DenseVector, SparseVector\n",
    "from pyspark.ml.functions import vector_to_array\n",
    "from pyspark.ml.classification import DecisionTreeClassifier, RandomForestClassifier\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
    "from sklearn.neighbors import KDTree\n",
    "\n",
    "from functools import reduce\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "import random\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c3ac74d9-7418-4f33-97f1-a379a4a9770a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "26d317d7-f671-4356-8cca-eec57af3997a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[2]: DataFrame[ActualElapsedTime: string, AirTime: string, ArrDelay: string, ArrTime: string, CRSArrTime: string, CRSDepTime: string, CRSElapsedTime: string, CancellationCode: string, Cancelled: string, CarrierDelay: string, DayOfWeek: string, DayofMonth: string, DepDelay: string, DepTime: string, Dest: string, Distance: string, Diverted: string, FlightNum: string, LateAircraftDelay: string, Month: string, NASDelay: string, Origin: string, SecurityDelay: string, TailNum: string, TaxiIn: string, TaxiOut: string, UniqueCarrier: string, WeatherDelay: string, Year: string]"
     ]
    }
   ],
   "source": [
    "df_vehicle_insurance = spark.read.format('csv').option('header','true').load('/mnt/team12/aug_train.csv')\n",
    "df_vehicle_insurance.cache()\n",
    "\n",
    "df_airplane = spark.read.format('csv').option('header','true').load('/mnt/team12/airline.csv')\n",
    "df_airplane.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "47c3dc76-c905-4af4-9379-f1436a45e9e9",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a049df9c-a346-454b-ac13-b0b55d01030f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "**Vehicle Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5a6300d6-6100-45e0-bb6c-4d99c3a141ef",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_vehicle_insurance = df_vehicle_insurance.drop('Region_Code', 'Policy_Sales_Channel')\n",
    "si = StringIndexer(inputCols=['Gender','Vehicle_Damage', 'Vehicle_Age'],\n",
    "                   outputCols=['Gender_Idx','Vehicle_Damage_Idx', 'Vehicle_Age_Idx']).fit(df_vehicle_insurance)\n",
    "indexed_df = si.transform(df_vehicle_insurance).select('Age', 'Annual_Premium', 'Vintage', 'Driving_License',\n",
    "                                          'Previously_Insured', F.col('Gender_Idx').alias('Gender'),\n",
    "                                          F.col('Vehicle_Damage_Idx').alias('Vehicle_Damage'),\n",
    "                                          F.col('Vehicle_Age_Idx').alias('Vehicle_Age'), 'Response')\n",
    "clean_df = indexed_df.select([F.col(c).cast('float').alias(c) for c in indexed_df.columns])\n",
    "\n",
    "@F.udf(T.FloatType())\n",
    "def fix_vehicle_age_encoding(x):\n",
    "\n",
    "  if x == 2.0:\n",
    "    return x\n",
    "  \n",
    "  return 1.0 - x\n",
    "\n",
    "\n",
    "clean_df = clean_df.select(\"*\", fix_vehicle_age_encoding(F.col('Vehicle_Age')).alias('Vehicle_Age_Fixed')) \\\n",
    "    .drop('Vehicle_Age').withColumnRenamed('Vehicle_Age_Fixed', 'Vehicle_Age')\n",
    "\n",
    "assembler = VectorAssembler(inputCols=[col for col in clean_df.columns if col != 'Response'], outputCol='features')\n",
    "features_df = assembler.transform(clean_df).select('features', 'Response')\n",
    "scaler = MinMaxScaler(inputCol='features', outputCol='scaledFeatures')\n",
    "model = scaler.fit(features_df)\n",
    "scaled_features_df = model.transform(features_df).select(F.col('scaledFeatures').alias('features'), 'Response')\n",
    "\n",
    "scaled_df = scaled_features_df.select(vector_to_array(F.col('features')).alias('fs'), 'Response').select([F.col('fs')[i] for i in range(8)] + ['Response'])\n",
    "original_column_names = [col for col in clean_df.columns if col != 'Response']\n",
    "columns_to_change = [col for col in scaled_df.columns if col != 'Response']\n",
    "scaled_vehicle_df = reduce(lambda scaled_df, idx: scaled_df.withColumnRenamed(columns_to_change[idx], original_column_names[idx]), range(len(columns_to_change)), scaled_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2addda56-3e26-4b1f-a6b2-8b99b0bf721b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+\n|Response| count|\n+--------+------+\n|     1.0| 62601|\n|     0.0|319553|\n+--------+------+\n\n"
     ]
    }
   ],
   "source": [
    "scaled_vehicle_df.groupBy('Response').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1e2af170-35f2-4a04-a0a2-e4bf4d02a6d0",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "**Airplane Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7c1047bb-34fd-4dfd-b178-35278fac367e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_airplane = df_airplane.drop('CancellationCode', 'FlightNum', 'Dest', 'Origin', 'TailNum', 'UniqueCarrier')\n",
    "df_airplane = df_airplane.withColumn('CarrierDelay', F.regexp_replace('CarrierDelay', 'NA', '0')) \\\n",
    "  .withColumn('DepDelay', F.regexp_replace('DepDelay', 'NA', '0')) \\\n",
    "  .withColumn('LateAircraftDelay', F.regexp_replace('LateAircraftDelay', 'NA', '0')) \\\n",
    "  .withColumn('NASDelay', F.regexp_replace('NASDelay', 'NA', '0')) \\\n",
    "  .withColumn('SecurityDelay', F.regexp_replace('SecurityDelay', 'NA', '0')) \\\n",
    "  .withColumn('WeatherDelay', F.regexp_replace('WeatherDelay', 'NA', '0'))\n",
    "\n",
    "df_airplane = df_airplane.withColumn('ActualElapsedTime', F.regexp_replace('ActualElapsedTime', 'NA', \"nan\")) \\\n",
    "  .withColumn('AirTime', F.regexp_replace('AirTime', 'NA', \"nan\")) \\\n",
    "  .withColumn('ArrDelay', F.regexp_replace('ArrDelay', 'NA', \"nan\")) \\\n",
    "  .withColumn('ArrTime', F.regexp_replace('ArrTime', 'NA', \"nan\")) \\\n",
    "  .withColumn('CRSElapsedTime', F.regexp_replace('CRSElapsedTime', 'NA', \"nan\")) \\\n",
    "  .withColumn('DepTime', F.regexp_replace('DepTime', 'NA', \"nan\")) \\\n",
    "  .withColumn('Distance', F.regexp_replace('Distance', 'NA', \"nan\")) \\\n",
    "  .withColumn('TaxiIn', F.regexp_replace('TaxiIn', 'NA', \"nan\")) \\\n",
    "  .withColumn('TaxiOut', F.regexp_replace('TaxiOut', 'NA', \"nan\"))\n",
    "\n",
    "df_airplane = df_airplane.select([F.col(c).cast('float').alias(c) for c in df_airplane.columns])\n",
    "\n",
    "imputer = Imputer(inputCols=['ActualElapsedTime', 'AirTime', 'ArrDelay', 'ArrTime', 'CRSElapsedTime', 'DepTime', 'Distance', 'TaxiIn', 'TaxiOut'], outputCols=['ActualElapsedTime', 'AirTime', 'ArrDelay', 'ArrTime', 'CRSElapsedTime', 'DepTime', 'Distance', 'TaxiIn', 'TaxiOut'])\n",
    "model = imputer.fit(df_airplane)\n",
    "imputed_airplane_df = model.transform(df_airplane)\n",
    "\n",
    "assembler = VectorAssembler(inputCols=[col for col in imputed_airplane_df.columns if col != 'Cancelled'], outputCol='features')\n",
    "features_airplane_df = assembler.transform(imputed_airplane_df).select('features', 'Cancelled')\n",
    "scaler = MinMaxScaler(inputCol='features', outputCol='scaledFeatures')\n",
    "model = scaler.fit(features_airplane_df)\n",
    "scaled_features_df = model.transform(features_airplane_df).select(F.col('scaledFeatures').alias('features'), 'Cancelled')\n",
    "\n",
    "scaled_df = scaled_features_df.select(vector_to_array(F.col('features')).alias('fs'), 'Cancelled').select([F.col('fs')[i] for i in range(len(imputed_airplane_df.columns) - 1)] + ['Cancelled'])\n",
    "original_column_names = [col for col in imputed_airplane_df.columns if col != 'Cancelled']\n",
    "columns_to_change = [col for col in scaled_df.columns if col != 'Cancelled']\n",
    "scaled_airplane_df = reduce(lambda scaled_df, idx: scaled_df.withColumnRenamed(columns_to_change[idx], original_column_names[idx]), range(len(columns_to_change)), scaled_df)\n",
    "\n",
    "smaller_scaled_airplane_df = scaled_airplane_df.limit(1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0c6ca184-7bd1-4ec0-8dfc-e267a129032c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+\n|Cancelled| count|\n+---------+------+\n|      0.0|981110|\n|      1.0| 18890|\n+---------+------+\n\n"
     ]
    }
   ],
   "source": [
    "smaller_scaled_airplane_df.groupBy('Cancelled').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3aa48d7d-b35e-489e-9b9d-396c6ff51c54",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Utilities\n",
    "\n",
    "Any utility functions are defined here, balance_score, classifier testing, etc.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f31cc74a-e067-4ce0-8b58-91ccba81cbaf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def balance_score(df, target_col_name):\n",
    "\n",
    "    \"\"\"\n",
    "    Function to calculate the balance score of a dataframe. The nearer to 1, the more balanced the target variable is.\n",
    "    This is calculated using Shannon's entropy.\n",
    "    Args:\n",
    "        df (pySpark DataFrame): DataFrame to perform calculation on\n",
    "        target_col_name (String): The target variable.\n",
    "    Returns:\n",
    "        Float: Balance score\n",
    "    \"\"\"\n",
    "\n",
    "    entropy = 0\n",
    "    counts = df.groupBy(target_col_name).count().select('count').rdd.collect()\n",
    "\n",
    "    n = df.count()\n",
    "    k = len(counts)\n",
    "\n",
    "    for count in counts:\n",
    "        ci = count.__getitem__('count')\n",
    "        entropy = entropy + (ci / n) * np.log(ci / n)\n",
    "    entropy = -1 * entropy\n",
    "\n",
    "    b = entropy / np.log(k)\n",
    "\n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3de2407e-d52e-4a4b-9864-05f0c9c9cfde",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def test_classifier(train, test, modelToUse='RandomForest', labelCol='Response', minority_label=1.0):\n",
    "    \"\"\"\n",
    "    A function to test an input df on either a RandomForest or DecisionTree Classifier\n",
    "    Author: Thomas Cotter\n",
    "\n",
    "    Args:\n",
    "    train (pySpark DataFrame): The input df for training\n",
    "    test (pySpark DataFrame): The input df for testing\n",
    "    modelToUse (String): The model to use, 'RandomForest' or 'DecisionTree'\n",
    "    labelCol (String): The name of column where the output labels are stored.\n",
    "    minority_label (Float): The value of the minority class\n",
    "\n",
    "    Returns:\n",
    "    Float: auc\n",
    "    Float: accuracy\n",
    "    [(Float, String)]: recall on both minority and majority class\n",
    "    Float: f1 score\n",
    "    [(Float, String)]: precision on both minority and majority class\n",
    "    \"\"\"\n",
    "    if 'features' not in train.columns:\n",
    "        assembler = VectorAssembler(inputCols=[col for col in train.columns if col != labelCol], outputCol='features')\n",
    "        train = assembler.transform(train)\n",
    "        test = assembler.transform(test)\n",
    "\n",
    "\n",
    "    if modelToUse == 'RandomForest':\n",
    "        rf = RandomForestClassifier(labelCol=labelCol, featuresCol='features', numTrees=100)\n",
    "        model = rf.fit(train)\n",
    "    elif modelToUse == \"DecisionTree\":\n",
    "        dt = DecisionTreeClassifier(labelCol=labelCol, featuresCol='features')\n",
    "        model = dt.fit(train)\n",
    "    else:\n",
    "        raise ValueError('Unrecognised input for modelToUse')\n",
    "\n",
    "    preds = model.transform(test)\n",
    "    bin_evaluator = BinaryClassificationEvaluator(labelCol=labelCol)\n",
    "    auc = bin_evaluator.evaluate(preds, {bin_evaluator.metricName: 'areaUnderROC'})\n",
    "\n",
    "    mc_evaluator = MulticlassClassificationEvaluator(labelCol=labelCol, metricName=\"accuracy\", metricLabel=minority_label)\n",
    "\n",
    "    acc = mc_evaluator.evaluate(preds)\n",
    "\n",
    "    mc_evaluator.setMetricName(\"f1\")\n",
    "    f1 = mc_evaluator.evaluate(preds)\n",
    "    mc_evaluator.setMetricName(\"precisionByLabel\")\n",
    "    prec = []\n",
    "    prec.append((mc_evaluator.evaluate(preds), \"minority\"))\n",
    "    mc_evaluator.setMetricLabel(0.0)\n",
    "    prec.append((mc_evaluator.evaluate(preds), \"majority\"))\n",
    "    mc_evaluator.setMetricLabel(1.0)\n",
    "    recall = []\n",
    "    mc_evaluator.setMetricName(\"recallByLabel\")\n",
    "    recall.append((mc_evaluator.evaluate(preds), 'minority'))\n",
    "    mc_evaluator.setMetricLabel(0.0)\n",
    "    recall.append((mc_evaluator.evaluate(preds), \"majority\"))\n",
    "\n",
    "\n",
    "\n",
    "    return auc, acc, recall, f1, prec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "894a93e6-2277-442d-bca5-2b7c155a7e7b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def scalability(f,og_df, cat_columns, target):\n",
    "    \"\"\"\n",
    "    Function to measure the scalability of a function f.\n",
    "    \n",
    "    f (function): The function to run. Must take a pyspark dataframe and a categorical array.\n",
    "    og_df (DataFrame): The original dataframe to test on.\n",
    "    \"\"\"\n",
    "    datasets =[]\n",
    "    sizes= [1/3, 1/2, 1]\n",
    "    og_size = og_df.count()\n",
    "    for size in sizes:\n",
    "        datasets.append(og_df.limit(int(og_size*size)))\n",
    "    times = []\n",
    "    data_sizes = []\n",
    "    for dataset in datasets:\n",
    "        tic = time.perf_counter()\n",
    "        data = f(dataset,cat_columns, target=target).collect()\n",
    "        toc = time.perf_counter()\n",
    "        data_sizes.append(dataset.count())\n",
    "        times.append(toc - tic)\n",
    "    sns.barplot(x=data_sizes,y=times)\n",
    "    plt.ylabel('Time in Seconds')\n",
    "    plt.xlabel('Data size(count)')\n",
    "    plt.title(f.__name__)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e73f47f8-53ee-4910-aff7-3f54f67ca3ea",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def get_metrics(train_df, test_df, labelCol, dataset):\n",
    "    \"\"\"\n",
    "    Function to get the metrics of the classifiers for an input dataset\n",
    "    \n",
    "    Args:\n",
    "        train_df (pySpark DataFrame): the training dataframe\n",
    "        test_df (pySpark DataFrrmae): the test dataframe\n",
    "        labelCol (string): The target label for this dataset\n",
    "        dataset (string): The name of the dataset\n",
    "    \"\"\"\n",
    "    \n",
    "    print(dataset)\n",
    "    \"\"\"\n",
    "    auc, acc, recall, f1, prec = test_classifier(train_df, test_df,\n",
    "                                                 modelToUse='RandomForest', labelCol=labelCol,\n",
    "                                                 minority_label=1.0)\n",
    "    print(\"-----RandomForest-----\")\n",
    "    print(\"AUC\", auc)\n",
    "    print(\"ACC\", acc)\n",
    "    print(\"RECALL BY LABEL\", recall)\n",
    "    print(\"F1\", f1)\n",
    "    print(\"PRECISION BY LABEL\", prec)\n",
    "    \"\"\"\n",
    "    auc, acc, recall, f1, prec = test_classifier(train_df, test_df,\n",
    "                                                 modelToUse='DecisionTree', labelCol=labelCol,\n",
    "                                                 minority_label=1.0)\n",
    "    print(\"-----DecisionTree-----\")\n",
    "    print(\"AUC\", auc)\n",
    "    print(\"ACC\", acc)\n",
    "    print(\"RECALL BY LABEL\", recall)\n",
    "    print(\"F1\", f1)\n",
    "    print(\"PRECISION BY LABEL\", prec)\n",
    "    print(\"-------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "63845d03-fee4-4c7e-baa6-87ce67b0e9bd",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# SMOTE & ENN Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "41a12c77-4c98-42c7-8524-4c182c3b0ed0",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "This section details the code for all of the SMOTE & ENN solutions implemented."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "aeb8aab2-7312-479a-84a3-1dd4022b53aa",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Local Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d9026e6c-775a-4b3b-a6be-99da5faad291",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "This solution randomly splits the data into partitions, and applys the imblearn SMOTE algorithm to each of those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7f24106d-3d2c-4754-a5d1-d401f74c963d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def LOCAL_SMOTENC(df, labelCol='Response', SIZE=10):\n",
    "    \"\"\"\n",
    "    A function to perform the SMOTE algorithm on our pyspark Dataframe in a Local Approach.\n",
    "\n",
    "    Args:\n",
    "    df (DataFrame): The original dataframe\n",
    "    labelCol (String): The target classification column.\n",
    "    SIZE (int): The number of splits the dataframe should be split into.\n",
    "\n",
    "    Returns:\n",
    "    Pandas DataFrame: The combined output of the SMOTE algorithm.\n",
    "    \"\"\"\n",
    "    splits = df.randomSplit([(1 / SIZE) for _ in range(SIZE)])\n",
    "\n",
    "    combined_pdf = None\n",
    "\n",
    "    for split in splits:\n",
    "        sm = SMOTENC(categorical_features=[2, 3, 4, 5, 6, 7],  random_state=42)\n",
    "        pdf = split.toPandas()\n",
    "        X = pdf.drop(labelCol, axis=1)\n",
    "        y = pdf[labelCol]\n",
    "        X_res, y_res = sm.fit_resample(X, y)\n",
    "        X_res[labelCol] = y_res\n",
    "        if combined_pdf is None:\n",
    "            combined_pdf = X_res\n",
    "        else:\n",
    "            combined_pdf = pd.concat([combined_pdf, X_res])\n",
    "\n",
    "    return spark.createDataFrame(combined_pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "51fc4e8e-6c9a-4a64-9753-fadff8f4fc43",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Global Approximate Solution\n",
    "\n",
    "This uses a BucketedRandomProjection LSH to group the rows to approximately find the nearest neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ee8f3c70-d1b1-445d-83bd-665a6b8950cd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def GLOBAL_APPROX_SMOTENC(df, categorical_columns, target='Response', k=5, num_synthetic=5, minority_label=1):\n",
    "    \"\"\"\n",
    "    A function to apply the SMOTENC algorithm to an input dataframe. This uses approximate nearest neighbors in order to create a Global solution.\n",
    "\n",
    "    Args:\n",
    "        df (DataFrame): The input pyspark Dataframe\n",
    "        categorical_columns ([Int]): The indices of columns in the DataFrame that refere to categorical variables.\n",
    "        k (Int): The number of nearest neighbors to find.\n",
    "        num_synthetic (Int): The number of synethetic samples to generate per point.\n",
    "        minority_label (Int): The label for the minority class (defaults to 1 in our situation)\n",
    "    \n",
    "    Returns\n",
    "        DataFrame: The dataframe with the additional synthetic samples.\n",
    "    \"\"\"\n",
    "\n",
    "    majority_df = df.filter(F.col(target) != minority_label)\n",
    "    minority_df = df.filter(F.col(target) == minority_label)\n",
    "    assembler = VectorAssembler(inputCols=[col for col in df.columns if col != target], outputCol='features')\n",
    "    minority_features_df = assembler.transform(minority_df).select('features')\n",
    "\n",
    "\n",
    "\n",
    "    brp = BucketedRandomProjectionLSH(inputCol='features', outputCol='hashes', bucketLength=2.0, numHashTables=3)\n",
    "    model = brp.fit(minority_features_df)\n",
    "\n",
    "    self_join_w_distance = model.approxSimilarityJoin(minority_features_df, minority_features_df, float('inf'),\n",
    "                                                      distCol='EuclideanDistance').filter(F.col('EuclideanDistance') > 0.0)\n",
    "\n",
    "    window_partition = Window.partitionBy('datasetA').orderBy('EuclideanDistance')\n",
    "\n",
    "    self_similarity_df = self_join_w_distance.withColumn('r_num', F.row_number().over(window_partition)).filter(F.col('r_num') <= k) \\\n",
    "                                          .select(F.col('datasetA.features').alias('features_A'), F.col('datasetB.features').alias('features_B')) \\\n",
    "                                          .groupBy('features_A').agg(F.collect_list('features_B').alias('nearest_neighbors'))\n",
    "\n",
    "    self_similarity_df.cache()\n",
    "\n",
    "    @F.udf(T.ArrayType(VectorUDT()))\n",
    "    def synthetic_vectors(feature, nearest_neighbors, categorical_columns, num_synthetic):\n",
    "      syn = []\n",
    "      if isinstance(feature, SparseVector):\n",
    "        feature = DenseVector(feature.toArray())\n",
    "      for _ in range(num_synthetic):\n",
    "        r_nn = random.choice(nearest_neighbors)\n",
    "        if isinstance(r_nn, SparseVector):\n",
    "          r_nn = DenseVector(r_nn.toArray())\n",
    "        synthetic = feature + (random.uniform(0, 1) * (random.choice(nearest_neighbors) - feature))\n",
    "        synthetic = DenseVector([round(synthetic[i]) if i in categorical_columns else synthetic[i] for i in range(len(synthetic))])\n",
    "        syn.append(synthetic)\n",
    "      return syn\n",
    "\n",
    "    categorical_columns = F.array([F.lit(i) for i in categorical_columns])\n",
    "    num_synthetic = F.lit(num_synthetic)\n",
    "    with_synthetic_df = self_similarity_df.select(synthetic_vectors(F.col('features_A'), F.col('nearest_neighbors'), categorical_columns, num_synthetic).alias('synthetic_features'))\n",
    "\n",
    "    exploded_df = with_synthetic_df.select(F.explode(F.col('synthetic_features')).alias('features'))\n",
    "\n",
    "    new_minority_features_df = minority_features_df.union(exploded_df)\n",
    "    nmfdf_split = new_minority_features_df.select(vector_to_array(F.col('features')).alias('fs')).select([F.col('fs')[i] for i in range(len(df.columns) - 1)])\n",
    "    og_columns = minority_df.columns\n",
    "    columns_to_change = nmfdf_split.columns\n",
    "    new_minority_df = reduce(lambda nmfdf_split, idx: nmfdf_split.withColumnRenamed(columns_to_change[idx], og_columns[idx]), range(len(columns_to_change)), nmfdf_split)\n",
    "    new_minority_df = new_minority_df.select(\"*\", F.lit(1.0).alias(target))\n",
    "\n",
    "    new_minority_df = new_minority_df.limit(majority_df.count())\n",
    "\n",
    "    new_df = majority_df.union(new_minority_df)\n",
    "\n",
    "    return new_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "60cfefb7-6bef-471f-bdcc-0a5b41a537e8",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Global Exact Solution\n",
    "\n",
    "This uses a kd-tree to query for the nearest neighbors quickly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "43178ea5-3433-49f8-9c0c-f659fd2b44e1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def GLOBAL_EXACT_SMOTENC(df, categorical_columns, target='Response', num_synthetic=5, minority_label=1.0):\n",
    "\n",
    "    \"\"\"\n",
    "    A function to run the SMOTE algorithm on an input DataFrame. This version uses an exact NearestNeighbors algorithm to produce the most accurate results. This is a global solution.\n",
    "\n",
    "    Args:\n",
    "        df (DataFrame): The input pyspark Dataframe\n",
    "        categorical_columns ([Int]): The indices of columns in the DataFrame that refere to categorical variables.\n",
    "        k (Int): The number of nearest neighbors to find.\n",
    "        num_synthetic (Int): The number of synethetic samples to generate per point.\n",
    "        minority_label (Int): The label for the minority class (defaults to 1 in our situation)\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: The original dataframe with additional synthetic rows.\n",
    "    \"\"\"\n",
    "\n",
    "    majority_df = df.filter(F.col(target) != minority_label)\n",
    "    minority_df = df.filter(F.col(target) == minority_label)\n",
    "\n",
    "    assembler = VectorAssembler(inputCols=[col for col in df.columns if col != target], outputCol='features')\n",
    "    minority_df = assembler.transform(minority_df).select('features')\n",
    "\n",
    "    minority_df.cache()\n",
    "\n",
    "    # Broadcast the minority df as a list, & broadcast the KDTree for use in MapPartitions\n",
    "    minority_data = minority_df.rdd.map(lambda x: x[0]).collect()\n",
    "    bc_minority_data = sc.broadcast(minority_data)\n",
    "    tree = KDTree(minority_data)\n",
    "    print(\"KDTree generated (EXACT_SMOTE)\")\n",
    "    bc_tree = sc.broadcast(tree)\n",
    "\n",
    "    def getNearestNeighbors(partition, tree_broadcast, data_broadcast):\n",
    "        # Get the value of the broadcast variables (ONLY DO THIS WITHIN A MAPPARTITION FUNCTION)\n",
    "        tree = tree_broadcast.value\n",
    "        data = data_broadcast.value\n",
    "        for row in partition:\n",
    "            features = row['features'].toArray()\n",
    "            # Get top 6 nearest neighbors, filter first one out as it will always be itself.\n",
    "            dist, ind = tree.query(features.reshape(1, -1), k=6)\n",
    "            ind = ind[0][1:]\n",
    "\n",
    "            neighbors = [DenseVector(data[idx]) for idx in ind]\n",
    "            # Return as DenseVectors for use later in the algorithm\n",
    "            yield [DenseVector(features), neighbors]\n",
    "\n",
    "\n",
    "    minority_df = minority_df.repartition(5)\n",
    "\n",
    "    with_neighbors_df = minority_df.rdd \\\n",
    "                                 .mapPartitions(lambda partition: getNearestNeighbors(partition, bc_tree, bc_minority_data)) \\\n",
    "                                 .toDF(['feature', 'neighbors'])\n",
    "\n",
    "    print(\"NearestNeighbors done (EXACT_SMOTE)\")\n",
    "\n",
    "\n",
    "    # This calculates the synthetic features for each feature and returns them as a list of DenseVectors\n",
    "    @F.udf(T.ArrayType(VectorUDT()))\n",
    "    def synthetic_vectors(feature, nearest_neighbors, categorical_columns, num_synthetic):\n",
    "      syn = []\n",
    "      if isinstance(feature, SparseVector):\n",
    "        feature = DenseVector(feature.toArray())\n",
    "      for _ in range(num_synthetic):\n",
    "        r_nn = random.choice(nearest_neighbors)\n",
    "        if isinstance(r_nn, SparseVector):\n",
    "          r_nn = DenseVector(r_nn.toArray())\n",
    "        synthetic = feature + (random.uniform(0, 1) * (random.choice(nearest_neighbors) - feature))\n",
    "        synthetic = DenseVector([round(synthetic[i]) if i in categorical_columns else synthetic[i] for i in range(len(synthetic))])\n",
    "        syn.append(synthetic)\n",
    "      return syn\n",
    "\n",
    "    categorical_columns = F.array([F.lit(i) for i in categorical_columns])\n",
    "    num_synthetic = F.lit(num_synthetic)\n",
    "    with_synthetic_df = with_neighbors_df.select(synthetic_vectors(F.col('feature'), F.col('neighbors'), categorical_columns, num_synthetic).alias('synthetic_features'))\n",
    "\n",
    "    # Turn the list of DenseVectors into rows of DenseVectors\n",
    "    exploded_df = with_synthetic_df.select(F.explode(F.col('synthetic_features')).alias('features'))\n",
    "\n",
    "    print(\"Synthetic Features done (EXACT_SMOTE)\")\n",
    "\n",
    "    # Add the synthetic features to the old minority dataframe\n",
    "    # This might need some optimization\n",
    "    new_minority_features_df = minority_df.union(exploded_df)\n",
    "    nmfdf_split = new_minority_features_df.select(vector_to_array(F.col('features')).alias('fs')).select([F.col('fs')[i] for i in range(len(df.columns) - 1)])\n",
    "    og_columns = majority_df.columns\n",
    "    columns_to_change = nmfdf_split.columns\n",
    "    new_minority_df = reduce(lambda nmfdf_split, idx: nmfdf_split.withColumnRenamed(columns_to_change[idx], og_columns[idx]), range(len(columns_to_change)), nmfdf_split)\n",
    "    new_minority_df = new_minority_df.select(\"*\", F.lit(minority_label).alias(target))\n",
    "\n",
    "    # Limit so that we never have more than the majority class\n",
    "    new_minority_df = new_minority_df.limit(majority_df.count())\n",
    "\n",
    "    # Union the majority and minority dataframes together to create the final dataframe.\n",
    "    new_df = majority_df.union(new_minority_df)\n",
    "\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1a070990-eeb6-45d6-b952-0f6a28fc83fb",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## ENN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5f4cd97f-7132-4fae-8f45-2a6a7e0c9ddc",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "This uses a KDTREE similar to exact-smotenc to calculate the nearest neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5f83391d-ad7d-489c-910b-5354f0835132",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def GLOBAL_EXACT_ENN(df, target='Response', target_label=0.0):\n",
    "\n",
    "    \"\"\"\n",
    "    A function to run the ENN algorithm on an input DataFrame. This version uses an exact NearestNeighbors algorithm to produce the most accurate results. This is a global solution refering to the GLOBAL_EXACT_SMOTENC function.\n",
    "\n",
    "    Args:\n",
    "    df (DataFrame): The input PySpark DataFrame\n",
    "    target_label (Float): The input target label to be downsampled, default 0.0 as the majority label\n",
    "\n",
    "    Returns:\n",
    "    DataFrame: The original dataframe with additional synthetic rows.\n",
    "    \"\"\"\n",
    "    NN = 3\n",
    "    assembler = VectorAssembler(inputCols=[col for col in df.columns if col != target], outputCol='features')\n",
    "    feature_df = assembler.transform(df).select('features', target)\n",
    "    feature_df.cache()\n",
    "\n",
    "    def getNearestNeighbors(partition, tree_broadcast, data_broadcast):\n",
    "        # Get the value of the broadcast variables (ONLY DO THIS WITHIN A MAPPARTITION FUNCTION)\n",
    "        tree = tree_broadcast.value\n",
    "        data = data_broadcast.value\n",
    "        for row in partition:\n",
    "            features = row['features'].toArray()\n",
    "            # Get top (NN+1=4) nearest neighbors, filter first one out as it will always be itself.\n",
    "            dist, ind = tree.query(features.reshape(1, -1), k = NN+1)\n",
    "            ind = ind[0][1:]\n",
    "            sum_response = 0\n",
    "            for idx in ind: sum_response += data[idx][0]\n",
    "            # Return as DenseVectors for use later in the algorithm\n",
    "            yield [DenseVector(features), row[target], sum_response]\n",
    "\n",
    "\n",
    "    feature_df = feature_df.repartition(5)\n",
    "\n",
    "    # Broadcast the minority df as a list, & broadcast the KDTree for use in MapPartitions\n",
    "    data = feature_df.rdd.map(lambda x: x[0]).collect()\n",
    "    bc_data = sc.broadcast(data)\n",
    "    target_column = feature_df.select(target).collect()\n",
    "    bc_tc = sc.broadcast(target_column)\n",
    "    tree = KDTree(data)\n",
    "    bc_tree = sc.broadcast(tree)\n",
    "\n",
    "    with_neighbors_df = feature_df.rdd\\\n",
    "                        .mapPartitions(lambda partition: getNearestNeighbors(partition, bc_tree, bc_tc)) \\\n",
    "                        .toDF(['features', target, 'NN_sum'])\n",
    "\n",
    "    # most of the neighbours (2 out of 3) will have to be majority group to not be excluded\n",
    "    if target_label == 1: #min\n",
    "        filterKey = \"NN_sum >= \" + str((NN+1)//2) #[NN_sum >= 2] for k =3\n",
    "    else: #Maj\n",
    "        filterKey = \"NN_sum <= \" + str((NN-1)//2) #[NN_sum <= 1] for k =3\n",
    "\n",
    "    new_target_features_df = with_neighbors_df.filter(F.col(target) == target_label)\\\n",
    "                      .filter(filterKey)\\\n",
    "                      .select('features', target)\n",
    "\n",
    "    nmfdf_split = new_target_features_df.select(vector_to_array(F.col('features')).alias('fs'), target).select([F.col('fs')[i] for i in range(len(df.columns) - 1)] + [target])\n",
    "    og_columns = df.columns\n",
    "    columns_to_change = nmfdf_split.columns\n",
    "    new_target_df = reduce(lambda nmfdf_split, idx: nmfdf_split.withColumnRenamed(columns_to_change[idx], og_columns[idx]), range(len(columns_to_change)), nmfdf_split)\n",
    "\n",
    "    # Union the majority and minority dataframes together to create the final dataframe.\n",
    "    new_df = new_target_df.union(df.filter(F.col(target) != target_label))\n",
    "\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c212554a-4d5c-4728-810a-4bf056628713",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Testing Solutions\n",
    "\n",
    "In this section we test our solutions on both the vehicle and airplane datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9e1753d1-d75f-4d26-897d-5eb87d5ee830",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-1625739156208097>:4\u001B[0m\n",
       "\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# It's best practice to split before re-sampling.\u001B[39;00m\n",
       "\u001B[1;32m      3\u001B[0m train_vehicle, test_vehicle \u001B[38;5;241m=\u001B[39m scaled_vehicle_df\u001B[38;5;241m.\u001B[39mrandomSplit([\u001B[38;5;241m0.7\u001B[39m, \u001B[38;5;241m0.3\u001B[39m], seed\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m42\u001B[39m)\n",
       "\u001B[0;32m----> 4\u001B[0m train_airplane, test_airplane \u001B[38;5;241m=\u001B[39m smaller_scaled_airplane_df\u001B[38;5;241m.\u001B[39mrandomSplit([\u001B[38;5;241m0.7\u001B[39m, \u001B[38;5;241m0.3\u001B[39m], seed\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m42\u001B[39m)\n",
       "\n",
       "\u001B[0;31mNameError\u001B[0m: name 'smaller_scaled_airplane_df' is not defined"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)\nFile \u001B[0;32m<command-1625739156208097>:4\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# It's best practice to split before re-sampling.\u001B[39;00m\n\u001B[1;32m      3\u001B[0m train_vehicle, test_vehicle \u001B[38;5;241m=\u001B[39m scaled_vehicle_df\u001B[38;5;241m.\u001B[39mrandomSplit([\u001B[38;5;241m0.7\u001B[39m, \u001B[38;5;241m0.3\u001B[39m], seed\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m42\u001B[39m)\n\u001B[0;32m----> 4\u001B[0m train_airplane, test_airplane \u001B[38;5;241m=\u001B[39m smaller_scaled_airplane_df\u001B[38;5;241m.\u001B[39mrandomSplit([\u001B[38;5;241m0.7\u001B[39m, \u001B[38;5;241m0.3\u001B[39m], seed\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m42\u001B[39m)\n\n\u001B[0;31mNameError\u001B[0m: name 'smaller_scaled_airplane_df' is not defined",
       "errorSummary": "<span class='ansi-red-fg'>NameError</span>: name 'smaller_scaled_airplane_df' is not defined",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# It's best practice to split before re-sampling.\n",
    "\n",
    "train_vehicle, test_vehicle = scaled_vehicle_df.randomSplit([0.7, 0.3], seed=42)\n",
    "train_airplane, test_airplane = smaller_scaled_airplane_df.randomSplit([0.7, 0.3], seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "59edb36a-739f-492e-ac07-fdb91256d76b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "**Balance Score (Pre-SMOTE)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a4fc9ea3-db4e-42ad-9b89-74447fc317fc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vehicle Balance Score: 0.643411338761781\nAirplane Balance Score: 0.13333966066057337\n"
     ]
    }
   ],
   "source": [
    "print(\"Vehicle Balance Score:\", balance_score(train_vehicle, 'Response'))\n",
    "print(\"Airplane Balance Score:\", balance_score(train_airplane, 'Cancelled'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3fd5c5fd-6e21-4f66-b36e-b90665c3977b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "**Metrics (Pre-SMOTE)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6ca6e863-ea49-4fce-b7dc-eadcbcc06b9d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-SMOTE metrics\nVehicle Dataset\n-----DecisionTree-----\nAUC 0.5\nACC 0.8362508831148442\nRECALL BY LABEL [(0.0, 'minority'), (1.0, 'majority')]\nF1 0.7616775528233958\nPRECISION BY LABEL [(0.0, 'minority'), (0.8362508831148442, 'majority')]\n-------------------------\nAirplane Dataset\n-----DecisionTree-----\nAUC 0.999848637091708\nACC 0.9988413868632636\nRECALL BY LABEL [(0.9996444444444444, 'minority'), (0.9988155207624234, 'majority')]\nF1 0.9988549250758533\nPRECISION BY LABEL [(0.9440899932840833, 'minority'), (1.0, 'majority')]\n-------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"Pre-SMOTE metrics\")\n",
    "get_metrics(train_vehicle, test_vehicle, \"Response\", 'Vehicle Dataset')\n",
    "get_metrics(train_airplane, test_airplane, \"Cancelled\", \"Airplane Dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "877d9a69-7cbd-43c4-9ef1-75bf69d0622b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Local SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ef2370ea-5d34-48de-af5e-8d0d940ab5e2",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "**Vehicle Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "74b7df4a-a497-498d-bcb2-3cefa9295398",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local Vehicle Balance Score: 1.0\nVehicle Dataset\n-----DecisionTree-----\nAUC 0.8543359443086569\nACC 0.7871627809613523\nRECALL BY LABEL [(0.8871844039629274, 'minority'), (0.767577208298132, 'majority')]\nF1 0.8118398645275665\nPRECISION BY LABEL [(0.42773497688751927, 'minority'), (0.9720252010936323, 'majority')]\n-------------------------\n"
     ]
    }
   ],
   "source": [
    "vehicle_local_df = LOCAL_SMOTENC(train_vehicle)\n",
    "print(\"Local Vehicle Balance Score:\", balance_score(vehicle_local_df, 'Response'))\n",
    "\n",
    "get_metrics(vehicle_local_df, test_vehicle, \"Response\", \"Vehicle Dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b8992bbb-8322-41a7-a9fd-7f79ad7cc880",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+\n|Response| count|\n+--------+------+\n|     0.0|223676|\n|     1.0|223676|\n+--------+------+\n\n"
     ]
    }
   ],
   "source": [
    "vehicle_local_df.groupBy(\"Response\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "15608f26-9452-49df-b186-104afff1c8fb",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "**Airplane Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "abf7424e-6541-4318-a465-add79c71df02",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# airplane_local_df = LOCAL_SMOTENC(train_airplane)\n",
    "# print(\"Local Airplane Balance Score:\", balance_score(airplane_local_df, 'Cancelled'))\n",
    "# get_metrics(airplane_local_df, test_airplane, \"Cancelled\", \"Airplane Dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c64101f7-23fa-42a5-8e3c-a8923a0969b1",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# airplane_local_df.groupBy(\"Cancelled\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b98fe840-5411-4241-bd2f-9606de282208",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Approx SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "59f56e1f-a825-4de4-b887-3f0bec0215f7",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "**Vehicle dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4d652006-77ad-412a-b260-ec900dc47b41",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approx Vehicle Balance Score: 1.0\nVehicle Dataset\n-----DecisionTree-----\nAUC 0.8343649957592822\nACC 0.8301628420162057\nRECALL BY LABEL [(0.059337381485032495, 'minority'), (0.9811007853812698, 'majority')]\nF1 0.7746274328650636\nPRECISION BY LABEL [(0.38072453861927547, 'minority'), (0.8419333184157529, 'majority')]\n-------------------------\n"
     ]
    }
   ],
   "source": [
    "vehicle_approx_df = GLOBAL_APPROX_SMOTENC(train_vehicle, [2, 3, 4, 5, 6, 7])\n",
    "print(\"Approx Vehicle Balance Score:\", balance_score(vehicle_approx_df, 'Response'))\n",
    "\n",
    "get_metrics(vehicle_approx_df, test_vehicle, 'Response', 'Vehicle Dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7e7d4b3c-8de5-4d91-992e-bbeb612ce476",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+\n|Response| count|\n+--------+------+\n|     0.0|223676|\n|     1.0|223676|\n+--------+------+\n\n"
     ]
    }
   ],
   "source": [
    "vehicle_approx_df.groupBy(\"Response\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8730a845-5efe-427b-a6b2-c2e5a4bd16ec",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "**Airplane Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "56c43b2f-1f4c-4798-932e-36fa899198fd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mPy4JJavaError\u001B[0m                             Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-1625739156208114>:2\u001B[0m\n",
       "\u001B[1;32m      1\u001B[0m airplane_approx_df \u001B[38;5;241m=\u001B[39m GLOBAL_APPROX_SMOTENC(train_airplane, [\u001B[38;5;241m7\u001B[39m, \u001B[38;5;241m8\u001B[39m, \u001B[38;5;241m9\u001B[39m, \u001B[38;5;241m10\u001B[39m, \u001B[38;5;241m11\u001B[39m, \u001B[38;5;241m12\u001B[39m], target\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mCancelled\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
       "\u001B[0;32m----> 2\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mApprox Airplane Balance Score:\u001B[39m\u001B[38;5;124m\"\u001B[39m, balance_score(airplane_approx_df, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mCancelled\u001B[39m\u001B[38;5;124m'\u001B[39m))\n",
       "\u001B[1;32m      3\u001B[0m get_metrics(airplane_approx_df, test_airplane, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mCancelled\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mAirplane Dataset\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
       "\n",
       "File \u001B[0;32m<command-1625739156208080>:14\u001B[0m, in \u001B[0;36mbalance_score\u001B[0;34m(df, target_col_name)\u001B[0m\n",
       "\u001B[1;32m      3\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n",
       "\u001B[1;32m      4\u001B[0m \u001B[38;5;124;03mFunction to calculate the balance score of a dataframe. The nearer to 1, the more balanced the target variable is.\u001B[39;00m\n",
       "\u001B[1;32m      5\u001B[0m \u001B[38;5;124;03mThis is calculated using Shannon's entropy.\u001B[39;00m\n",
       "\u001B[0;32m   (...)\u001B[0m\n",
       "\u001B[1;32m     10\u001B[0m \u001B[38;5;124;03m    Float: Balance score\u001B[39;00m\n",
       "\u001B[1;32m     11\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n",
       "\u001B[1;32m     13\u001B[0m entropy \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n",
       "\u001B[0;32m---> 14\u001B[0m counts \u001B[38;5;241m=\u001B[39m \u001B[43mdf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgroupBy\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtarget_col_name\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcount\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mselect\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mcount\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrdd\u001B[49m\u001B[38;5;241m.\u001B[39mcollect()\n",
       "\u001B[1;32m     16\u001B[0m n \u001B[38;5;241m=\u001B[39m df\u001B[38;5;241m.\u001B[39mcount()\n",
       "\u001B[1;32m     17\u001B[0m k \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(counts)\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/instrumentation_utils.py:84\u001B[0m, in \u001B[0;36m_wrap_property.<locals>.wrapper\u001B[0;34m(self)\u001B[0m\n",
       "\u001B[1;32m     82\u001B[0m start \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mperf_counter()\n",
       "\u001B[1;32m     83\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
       "\u001B[0;32m---> 84\u001B[0m     res \u001B[38;5;241m=\u001B[39m \u001B[43mprop\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m     85\u001B[0m     logger\u001B[38;5;241m.\u001B[39mlog_success(\n",
       "\u001B[1;32m     86\u001B[0m         module_name, class_name, property_name, time\u001B[38;5;241m.\u001B[39mperf_counter() \u001B[38;5;241m-\u001B[39m start\n",
       "\u001B[1;32m     87\u001B[0m     )\n",
       "\u001B[1;32m     88\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m res\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/sql/dataframe.py:216\u001B[0m, in \u001B[0;36mDataFrame.rdd\u001B[0;34m(self)\u001B[0m\n",
       "\u001B[1;32m    201\u001B[0m \u001B[38;5;124;03m\"\"\"Returns the content as an :class:`pyspark.RDD` of :class:`Row`.\u001B[39;00m\n",
       "\u001B[1;32m    202\u001B[0m \n",
       "\u001B[1;32m    203\u001B[0m \u001B[38;5;124;03m.. versionadded:: 1.3.0\u001B[39;00m\n",
       "\u001B[0;32m   (...)\u001B[0m\n",
       "\u001B[1;32m    213\u001B[0m \u001B[38;5;124;03m<class 'pyspark.rdd.RDD'>\u001B[39;00m\n",
       "\u001B[1;32m    214\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n",
       "\u001B[1;32m    215\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lazy_rdd \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
       "\u001B[0;32m--> 216\u001B[0m     jrdd \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jdf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjavaToPython\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m    217\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lazy_rdd \u001B[38;5;241m=\u001B[39m RDD(\n",
       "\u001B[1;32m    218\u001B[0m         jrdd, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msparkSession\u001B[38;5;241m.\u001B[39m_sc, BatchedSerializer(CPickleSerializer())\n",
       "\u001B[1;32m    219\u001B[0m     )\n",
       "\u001B[1;32m    220\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lazy_rdd\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1321\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n",
       "\u001B[1;32m   1315\u001B[0m command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1316\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1317\u001B[0m     args_command \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1318\u001B[0m     proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n",
       "\u001B[1;32m   1320\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39msend_command(command)\n",
       "\u001B[0;32m-> 1321\u001B[0m return_value \u001B[38;5;241m=\u001B[39m \u001B[43mget_return_value\u001B[49m\u001B[43m(\u001B[49m\n",
       "\u001B[1;32m   1322\u001B[0m \u001B[43m    \u001B[49m\u001B[43manswer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgateway_client\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtarget_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m   1324\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m temp_arg \u001B[38;5;129;01min\u001B[39;00m temp_args:\n",
       "\u001B[1;32m   1325\u001B[0m     temp_arg\u001B[38;5;241m.\u001B[39m_detach()\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/errors/exceptions.py:228\u001B[0m, in \u001B[0;36mcapture_sql_exception.<locals>.deco\u001B[0;34m(*a, **kw)\u001B[0m\n",
       "\u001B[1;32m    226\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdeco\u001B[39m(\u001B[38;5;241m*\u001B[39ma: Any, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkw: Any) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Any:\n",
       "\u001B[1;32m    227\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n",
       "\u001B[0;32m--> 228\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43ma\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkw\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m    229\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m Py4JJavaError \u001B[38;5;28;01mas\u001B[39;00m e:\n",
       "\u001B[1;32m    230\u001B[0m         converted \u001B[38;5;241m=\u001B[39m convert_exception(e\u001B[38;5;241m.\u001B[39mjava_exception)\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/protocol.py:326\u001B[0m, in \u001B[0;36mget_return_value\u001B[0;34m(answer, gateway_client, target_id, name)\u001B[0m\n",
       "\u001B[1;32m    324\u001B[0m value \u001B[38;5;241m=\u001B[39m OUTPUT_CONVERTER[\u001B[38;5;28mtype\u001B[39m](answer[\u001B[38;5;241m2\u001B[39m:], gateway_client)\n",
       "\u001B[1;32m    325\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m answer[\u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m==\u001B[39m REFERENCE_TYPE:\n",
       "\u001B[0;32m--> 326\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m Py4JJavaError(\n",
       "\u001B[1;32m    327\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAn error occurred while calling \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[38;5;132;01m{2}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39m\n",
       "\u001B[1;32m    328\u001B[0m         \u001B[38;5;28mformat\u001B[39m(target_id, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m, name), value)\n",
       "\u001B[1;32m    329\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
       "\u001B[1;32m    330\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m Py4JError(\n",
       "\u001B[1;32m    331\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAn error occurred while calling \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[38;5;132;01m{2}\u001B[39;00m\u001B[38;5;124m. Trace:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{3}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39m\n",
       "\u001B[1;32m    332\u001B[0m         \u001B[38;5;28mformat\u001B[39m(target_id, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m, name, value))\n",
       "\n",
       "\u001B[0;31mPy4JJavaError\u001B[0m: An error occurred while calling o2286.javaToPython.\n",
       ": org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 12801.0 failed 4 times, most recent failure: Lost task 0.3 in stage 12801.0 (TID 1628053) (10.139.64.14 executor 10): org.apache.spark.memory.SparkOutOfMemoryError: [UNABLE_TO_ACQUIRE_MEMORY] Unable to acquire 1012 bytes of memory, got 0.\n",
       "\tat org.apache.spark.errors.SparkCoreErrors$.outOfMemoryError(SparkCoreErrors.scala:470)\n",
       "\tat org.apache.spark.errors.SparkCoreErrors.outOfMemoryError(SparkCoreErrors.scala)\n",
       "\tat org.apache.spark.memory.MemoryConsumer.throwOom(MemoryConsumer.java:187)\n",
       "\tat org.apache.spark.memory.MemoryConsumer.allocatePage(MemoryConsumer.java:148)\n",
       "\tat org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter.acquireNewPageIfNecessary(UnsafeExternalSorter.java:490)\n",
       "\tat org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter.allocateMemoryForRecordIfNecessary(UnsafeExternalSorter.java:509)\n",
       "\tat org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter.insertRecord(UnsafeExternalSorter.java:544)\n",
       "\tat org.apache.spark.sql.execution.UnsafeExternalRowSorter.insertRow(UnsafeExternalRowSorter.java:138)\n",
       "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage5.hashAgg_doAggregateWithKeysOutput_0$(Unknown Source)\n",
       "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage5.sort_addToSorter_0$(Unknown Source)\n",
       "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage5.processNext(Unknown Source)\n",
       "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
       "\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$2.hasNext(WholeStageCodegenExec.scala:780)\n",
       "\tat org.apache.spark.sql.execution.aggregate.ObjectHashAggregateExec.$anonfun$doExecute$1(ObjectHashAggregateExec.scala:109)\n",
       "\tat org.apache.spark.sql.execution.aggregate.ObjectHashAggregateExec.$anonfun$doExecute$1$adapted(ObjectHashAggregateExec.scala:107)\n",
       "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsWithIndexInternal$2(RDD.scala:916)\n",
       "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsWithIndexInternal$2$adapted(RDD.scala:916)\n",
       "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:60)\n",
       "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:406)\n",
       "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:370)\n",
       "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:60)\n",
       "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:406)\n",
       "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:370)\n",
       "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:60)\n",
       "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:406)\n",
       "\tat org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:419)\n",
       "\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1552)\n",
       "\tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1479)\n",
       "\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1543)\n",
       "\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1362)\n",
       "\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:417)\n",
       "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:368)\n",
       "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:60)\n",
       "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:406)\n",
       "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:370)\n",
       "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:60)\n",
       "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:406)\n",
       "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:370)\n",
       "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:60)\n",
       "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:406)\n",
       "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:370)\n",
       "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:60)\n",
       "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:406)\n",
       "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:370)\n",
       "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:60)\n",
       "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:406)\n",
       "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:370)\n",
       "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:60)\n",
       "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:406)\n",
       "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:370)\n",
       "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:60)\n",
       "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:406)\n",
       "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:370)\n",
       "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:60)\n",
       "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:406)\n",
       "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:370)\n",
       "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:60)\n",
       "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:406)\n",
       "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:370)\n",
       "\tat org.apache.spark.rdd.UnionRDD.compute(UnionRDD.scala:122)\n",
       "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:406)\n",
       "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:370)\n",
       "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:60)\n",
       "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:406)\n",
       "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:370)\n",
       "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:60)\n",
       "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:406)\n",
       "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:370)\n",
       "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n",
       "\tat org.apache.spark.scheduler.ShuffleMapTask.$anonfun$runTask$3(ShuffleMapTask.scala:81)\n",
       "\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n",
       "\tat org.apache.spark.scheduler.ShuffleMapTask.$anonfun$runTask$1(ShuffleMapTask.scala:81)\n",
       "\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n",
       "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)\n",
       "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)\n",
       "\tat org.apache.spark.scheduler.Task.doRunTask(Task.scala:174)\n",
       "\tat org.apache.spark.scheduler.Task.$anonfun$run$5(Task.scala:142)\n",
       "\tat com.databricks.unity.EmptyHandle$.runWithAndClose(UCSHandle.scala:125)\n",
       "\tat org.apache.spark.scheduler.Task.$anonfun$run$1(Task.scala:142)\n",
       "\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n",
       "\tat org.apache.spark.scheduler.Task.run(Task.scala:97)\n",
       "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$13(Executor.scala:904)\n",
       "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1713)\n",
       "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:907)\n",
       "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
       "\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n",
       "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:761)\n",
       "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
       "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
       "\tat java.lang.Thread.run(Thread.java:750)\n",
       "\n",
       "Driver stacktrace:\n",
       "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:3377)\n",
       "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:3309)\n",
       "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:3300)\n",
       "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
       "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
       "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
       "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:3300)\n",
       "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1429)\n",
       "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1429)\n",
       "\tat scala.Option.foreach(Option.scala:407)\n",
       "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1429)\n",
       "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3589)\n",
       "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3527)\n",
       "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3515)\n",
       "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:51)\n",
       "Caused by: org.apache.spark.memory.SparkOutOfMemoryError: [UNABLE_TO_ACQUIRE_MEMORY] Unable to acquire 1012 bytes of memory, got 0.\n",
       "\tat org.apache.spark.errors.SparkCoreErrors$.outOfMemoryError(SparkCoreErrors.scala:470)\n",
       "\tat org.apache.spark.errors.SparkCoreErrors.outOfMemoryError(SparkCoreErrors.scala)\n",
       "\tat org.apache.spark.memory.MemoryConsumer.throwOom(MemoryConsumer.java:187)\n",
       "\tat org.apache.spark.memory.MemoryConsumer.allocatePage(MemoryConsumer.java:148)\n",
       "\tat org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter.acquireNewPageIfNecessary(UnsafeExternalSorter.java:490)\n",
       "\tat org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter.allocateMemoryForRecordIfNecessary(UnsafeExternalSorter.java:509)\n",
       "\tat org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter.insertRecord(UnsafeExternalSorter.java:544)\n",
       "\tat org.apache.spark.sql.execution.UnsafeExternalRowSorter.insertRow(UnsafeExternalRowSorter.java:138)\n",
       "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage5.hashAgg_doAggregateWithKeysOutput_0$(Unknown Source)\n",
       "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage5.sort_addToSorter_0$(Unknown Source)\n",
       "\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage5.processNext(Unknown Source)\n",
       "\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n",
       "\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$2.hasNext(WholeStageCodegenExec.scala:780)\n",
       "\tat org.apache.spark.sql.execution.aggregate.ObjectHashAggregateExec.$anonfun$doExecute$1(ObjectHashAggregateExec.scala:109)\n",
       "\tat org.apache.spark.sql.execution.aggregate.ObjectHashAggregateExec.$anonfun$doExecute$1$adapted(ObjectHashAggregateExec.scala:107)\n",
       "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsWithIndexInternal$2(RDD.scala:916)\n",
       "\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsWithIndexInternal$2$adapted(RDD.scala:916)\n",
       "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:60)\n",
       "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:406)\n",
       "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:370)\n",
       "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:60)\n",
       "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:406)\n",
       "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:370)\n",
       "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:60)\n",
       "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:406)\n",
       "\tat org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:419)\n",
       "\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1552)\n",
       "\tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1479)\n",
       "\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1543)\n",
       "\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1362)\n",
       "\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:417)\n",
       "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:368)\n",
       "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:60)\n",
       "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:406)\n",
       "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:370)\n",
       "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:60)\n",
       "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:406)\n",
       "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:370)\n",
       "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:60)\n",
       "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:406)\n",
       "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:370)\n",
       "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:60)\n",
       "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:406)\n",
       "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:370)\n",
       "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:60)\n",
       "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:406)\n",
       "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:370)\n",
       "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:60)\n",
       "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:406)\n",
       "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:370)\n",
       "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:60)\n",
       "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:406)\n",
       "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:370)\n",
       "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:60)\n",
       "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:406)\n",
       "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:370)\n",
       "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:60)\n",
       "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:406)\n",
       "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:370)\n",
       "\tat org.apache.spark.rdd.UnionRDD.compute(UnionRDD.scala:122)\n",
       "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:406)\n",
       "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:370)\n",
       "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:60)\n",
       "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:406)\n",
       "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:370)\n",
       "\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:60)\n",
       "\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:406)\n",
       "\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:370)\n",
       "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n",
       "\tat org.apache.spark.scheduler.ShuffleMapTask.$anonfun$runTask$3(ShuffleMapTask.scala:81)\n",
       "\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n",
       "\tat org.apache.spark.scheduler.ShuffleMapTask.$anonfun$runTask$1(ShuffleMapTask.scala:81)\n",
       "\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n",
       "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)\n",
       "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)\n",
       "\tat org.apache.spark.scheduler.Task.doRunTask(Task.scala:174)\n",
       "\tat org.apache.spark.scheduler.Task.$anonfun$run$5(Task.scala:142)\n",
       "\tat com.databricks.unity.EmptyHandle$.runWithAndClose(UCSHandle.scala:125)\n",
       "\tat org.apache.spark.scheduler.Task.$anonfun$run$1(Task.scala:142)\n",
       "\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n",
       "\tat org.apache.spark.scheduler.Task.run(Task.scala:97)\n",
       "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$13(Executor.scala:904)\n",
       "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1713)\n",
       "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:907)\n",
       "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
       "\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n",
       "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:761)\n",
       "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
       "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
       "\tat java.lang.Thread.run(Thread.java:750)\n"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mPy4JJavaError\u001B[0m                             Traceback (most recent call last)\nFile \u001B[0;32m<command-1625739156208114>:2\u001B[0m\n\u001B[1;32m      1\u001B[0m airplane_approx_df \u001B[38;5;241m=\u001B[39m GLOBAL_APPROX_SMOTENC(train_airplane, [\u001B[38;5;241m7\u001B[39m, \u001B[38;5;241m8\u001B[39m, \u001B[38;5;241m9\u001B[39m, \u001B[38;5;241m10\u001B[39m, \u001B[38;5;241m11\u001B[39m, \u001B[38;5;241m12\u001B[39m], target\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mCancelled\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m----> 2\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mApprox Airplane Balance Score:\u001B[39m\u001B[38;5;124m\"\u001B[39m, balance_score(airplane_approx_df, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mCancelled\u001B[39m\u001B[38;5;124m'\u001B[39m))\n\u001B[1;32m      3\u001B[0m get_metrics(airplane_approx_df, test_airplane, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mCancelled\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mAirplane Dataset\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\nFile \u001B[0;32m<command-1625739156208080>:14\u001B[0m, in \u001B[0;36mbalance_score\u001B[0;34m(df, target_col_name)\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;124;03mFunction to calculate the balance score of a dataframe. The nearer to 1, the more balanced the target variable is.\u001B[39;00m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;124;03mThis is calculated using Shannon's entropy.\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     10\u001B[0m \u001B[38;5;124;03m    Float: Balance score\u001B[39;00m\n\u001B[1;32m     11\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     13\u001B[0m entropy \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m---> 14\u001B[0m counts \u001B[38;5;241m=\u001B[39m \u001B[43mdf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgroupBy\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtarget_col_name\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcount\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mselect\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mcount\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrdd\u001B[49m\u001B[38;5;241m.\u001B[39mcollect()\n\u001B[1;32m     16\u001B[0m n \u001B[38;5;241m=\u001B[39m df\u001B[38;5;241m.\u001B[39mcount()\n\u001B[1;32m     17\u001B[0m k \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(counts)\n\nFile \u001B[0;32m/databricks/spark/python/pyspark/instrumentation_utils.py:84\u001B[0m, in \u001B[0;36m_wrap_property.<locals>.wrapper\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     82\u001B[0m start \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mperf_counter()\n\u001B[1;32m     83\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 84\u001B[0m     res \u001B[38;5;241m=\u001B[39m \u001B[43mprop\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     85\u001B[0m     logger\u001B[38;5;241m.\u001B[39mlog_success(\n\u001B[1;32m     86\u001B[0m         module_name, class_name, property_name, time\u001B[38;5;241m.\u001B[39mperf_counter() \u001B[38;5;241m-\u001B[39m start\n\u001B[1;32m     87\u001B[0m     )\n\u001B[1;32m     88\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m res\n\nFile \u001B[0;32m/databricks/spark/python/pyspark/sql/dataframe.py:216\u001B[0m, in \u001B[0;36mDataFrame.rdd\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    201\u001B[0m \u001B[38;5;124;03m\"\"\"Returns the content as an :class:`pyspark.RDD` of :class:`Row`.\u001B[39;00m\n\u001B[1;32m    202\u001B[0m \n\u001B[1;32m    203\u001B[0m \u001B[38;5;124;03m.. versionadded:: 1.3.0\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    213\u001B[0m \u001B[38;5;124;03m<class 'pyspark.rdd.RDD'>\u001B[39;00m\n\u001B[1;32m    214\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    215\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lazy_rdd \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 216\u001B[0m     jrdd \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jdf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjavaToPython\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    217\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lazy_rdd \u001B[38;5;241m=\u001B[39m RDD(\n\u001B[1;32m    218\u001B[0m         jrdd, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msparkSession\u001B[38;5;241m.\u001B[39m_sc, BatchedSerializer(CPickleSerializer())\n\u001B[1;32m    219\u001B[0m     )\n\u001B[1;32m    220\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lazy_rdd\n\nFile \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1321\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m   1315\u001B[0m command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1316\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1317\u001B[0m     args_command \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1318\u001B[0m     proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n\u001B[1;32m   1320\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39msend_command(command)\n\u001B[0;32m-> 1321\u001B[0m return_value \u001B[38;5;241m=\u001B[39m \u001B[43mget_return_value\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1322\u001B[0m \u001B[43m    \u001B[49m\u001B[43manswer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgateway_client\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtarget_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1324\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m temp_arg \u001B[38;5;129;01min\u001B[39;00m temp_args:\n\u001B[1;32m   1325\u001B[0m     temp_arg\u001B[38;5;241m.\u001B[39m_detach()\n\nFile \u001B[0;32m/databricks/spark/python/pyspark/errors/exceptions.py:228\u001B[0m, in \u001B[0;36mcapture_sql_exception.<locals>.deco\u001B[0;34m(*a, **kw)\u001B[0m\n\u001B[1;32m    226\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdeco\u001B[39m(\u001B[38;5;241m*\u001B[39ma: Any, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkw: Any) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Any:\n\u001B[1;32m    227\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 228\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43ma\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkw\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    229\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m Py4JJavaError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    230\u001B[0m         converted \u001B[38;5;241m=\u001B[39m convert_exception(e\u001B[38;5;241m.\u001B[39mjava_exception)\n\nFile \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/protocol.py:326\u001B[0m, in \u001B[0;36mget_return_value\u001B[0;34m(answer, gateway_client, target_id, name)\u001B[0m\n\u001B[1;32m    324\u001B[0m value \u001B[38;5;241m=\u001B[39m OUTPUT_CONVERTER[\u001B[38;5;28mtype\u001B[39m](answer[\u001B[38;5;241m2\u001B[39m:], gateway_client)\n\u001B[1;32m    325\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m answer[\u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m==\u001B[39m REFERENCE_TYPE:\n\u001B[0;32m--> 326\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m Py4JJavaError(\n\u001B[1;32m    327\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAn error occurred while calling \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[38;5;132;01m{2}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39m\n\u001B[1;32m    328\u001B[0m         \u001B[38;5;28mformat\u001B[39m(target_id, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m, name), value)\n\u001B[1;32m    329\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    330\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m Py4JError(\n\u001B[1;32m    331\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAn error occurred while calling \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[38;5;132;01m{2}\u001B[39;00m\u001B[38;5;124m. Trace:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{3}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39m\n\u001B[1;32m    332\u001B[0m         \u001B[38;5;28mformat\u001B[39m(target_id, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m, name, value))\n\n\u001B[0;31mPy4JJavaError\u001B[0m: An error occurred while calling o2286.javaToPython.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 12801.0 failed 4 times, most recent failure: Lost task 0.3 in stage 12801.0 (TID 1628053) (10.139.64.14 executor 10): org.apache.spark.memory.SparkOutOfMemoryError: [UNABLE_TO_ACQUIRE_MEMORY] Unable to acquire 1012 bytes of memory, got 0.\n\tat org.apache.spark.errors.SparkCoreErrors$.outOfMemoryError(SparkCoreErrors.scala:470)\n\tat org.apache.spark.errors.SparkCoreErrors.outOfMemoryError(SparkCoreErrors.scala)\n\tat org.apache.spark.memory.MemoryConsumer.throwOom(MemoryConsumer.java:187)\n\tat org.apache.spark.memory.MemoryConsumer.allocatePage(MemoryConsumer.java:148)\n\tat org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter.acquireNewPageIfNecessary(UnsafeExternalSorter.java:490)\n\tat org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter.allocateMemoryForRecordIfNecessary(UnsafeExternalSorter.java:509)\n\tat org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter.insertRecord(UnsafeExternalSorter.java:544)\n\tat org.apache.spark.sql.execution.UnsafeExternalRowSorter.insertRow(UnsafeExternalRowSorter.java:138)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage5.hashAgg_doAggregateWithKeysOutput_0$(Unknown Source)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage5.sort_addToSorter_0$(Unknown Source)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage5.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$2.hasNext(WholeStageCodegenExec.scala:780)\n\tat org.apache.spark.sql.execution.aggregate.ObjectHashAggregateExec.$anonfun$doExecute$1(ObjectHashAggregateExec.scala:109)\n\tat org.apache.spark.sql.execution.aggregate.ObjectHashAggregateExec.$anonfun$doExecute$1$adapted(ObjectHashAggregateExec.scala:107)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsWithIndexInternal$2(RDD.scala:916)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsWithIndexInternal$2$adapted(RDD.scala:916)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:60)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:406)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:370)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:60)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:406)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:370)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:60)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:406)\n\tat org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:419)\n\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1552)\n\tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1479)\n\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1543)\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1362)\n\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:417)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:368)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:60)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:406)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:370)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:60)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:406)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:370)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:60)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:406)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:370)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:60)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:406)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:370)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:60)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:406)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:370)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:60)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:406)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:370)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:60)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:406)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:370)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:60)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:406)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:370)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:60)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:406)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:370)\n\tat org.apache.spark.rdd.UnionRDD.compute(UnionRDD.scala:122)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:406)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:370)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:60)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:406)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:370)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:60)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:406)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:370)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.$anonfun$runTask$3(ShuffleMapTask.scala:81)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.scheduler.ShuffleMapTask.$anonfun$runTask$1(ShuffleMapTask.scala:81)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)\n\tat org.apache.spark.scheduler.Task.doRunTask(Task.scala:174)\n\tat org.apache.spark.scheduler.Task.$anonfun$run$5(Task.scala:142)\n\tat com.databricks.unity.EmptyHandle$.runWithAndClose(UCSHandle.scala:125)\n\tat org.apache.spark.scheduler.Task.$anonfun$run$1(Task.scala:142)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:97)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$13(Executor.scala:904)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1713)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:907)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:761)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:3377)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:3309)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:3300)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:3300)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1429)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1429)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1429)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3589)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3527)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3515)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:51)\nCaused by: org.apache.spark.memory.SparkOutOfMemoryError: [UNABLE_TO_ACQUIRE_MEMORY] Unable to acquire 1012 bytes of memory, got 0.\n\tat org.apache.spark.errors.SparkCoreErrors$.outOfMemoryError(SparkCoreErrors.scala:470)\n\tat org.apache.spark.errors.SparkCoreErrors.outOfMemoryError(SparkCoreErrors.scala)\n\tat org.apache.spark.memory.MemoryConsumer.throwOom(MemoryConsumer.java:187)\n\tat org.apache.spark.memory.MemoryConsumer.allocatePage(MemoryConsumer.java:148)\n\tat org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter.acquireNewPageIfNecessary(UnsafeExternalSorter.java:490)\n\tat org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter.allocateMemoryForRecordIfNecessary(UnsafeExternalSorter.java:509)\n\tat org.apache.spark.util.collection.unsafe.sort.UnsafeExternalSorter.insertRecord(UnsafeExternalSorter.java:544)\n\tat org.apache.spark.sql.execution.UnsafeExternalRowSorter.insertRow(UnsafeExternalRowSorter.java:138)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage5.hashAgg_doAggregateWithKeysOutput_0$(Unknown Source)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage5.sort_addToSorter_0$(Unknown Source)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage5.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$2.hasNext(WholeStageCodegenExec.scala:780)\n\tat org.apache.spark.sql.execution.aggregate.ObjectHashAggregateExec.$anonfun$doExecute$1(ObjectHashAggregateExec.scala:109)\n\tat org.apache.spark.sql.execution.aggregate.ObjectHashAggregateExec.$anonfun$doExecute$1$adapted(ObjectHashAggregateExec.scala:107)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsWithIndexInternal$2(RDD.scala:916)\n\tat org.apache.spark.rdd.RDD.$anonfun$mapPartitionsWithIndexInternal$2$adapted(RDD.scala:916)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:60)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:406)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:370)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:60)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:406)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:370)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:60)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:406)\n\tat org.apache.spark.rdd.RDD.$anonfun$getOrCompute$1(RDD.scala:419)\n\tat org.apache.spark.storage.BlockManager.$anonfun$doPutIterator$1(BlockManager.scala:1552)\n\tat org.apache.spark.storage.BlockManager.org$apache$spark$storage$BlockManager$$doPut(BlockManager.scala:1479)\n\tat org.apache.spark.storage.BlockManager.doPutIterator(BlockManager.scala:1543)\n\tat org.apache.spark.storage.BlockManager.getOrElseUpdate(BlockManager.scala:1362)\n\tat org.apache.spark.rdd.RDD.getOrCompute(RDD.scala:417)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:368)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:60)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:406)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:370)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:60)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:406)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:370)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:60)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:406)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:370)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:60)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:406)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:370)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:60)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:406)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:370)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:60)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:406)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:370)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:60)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:406)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:370)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:60)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:406)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:370)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:60)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:406)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:370)\n\tat org.apache.spark.rdd.UnionRDD.compute(UnionRDD.scala:122)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:406)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:370)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:60)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:406)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:370)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:60)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:406)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:370)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.$anonfun$runTask$3(ShuffleMapTask.scala:81)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.scheduler.ShuffleMapTask.$anonfun$runTask$1(ShuffleMapTask.scala:81)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)\n\tat org.apache.spark.scheduler.Task.doRunTask(Task.scala:174)\n\tat org.apache.spark.scheduler.Task.$anonfun$run$5(Task.scala:142)\n\tat com.databricks.unity.EmptyHandle$.runWithAndClose(UCSHandle.scala:125)\n\tat org.apache.spark.scheduler.Task.$anonfun$run$1(Task.scala:142)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:97)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$13(Executor.scala:904)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1713)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$4(Executor.scala:907)\n\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n\tat com.databricks.spark.util.ExecutorFrameProfiler$.record(ExecutorFrameProfiler.scala:110)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:761)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\n",
       "errorSummary": "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 12801.0 failed 4 times, most recent failure: Lost task 0.3 in stage 12801.0 (TID 1628053) (10.139.64.14 executor 10): org.apache.spark.memory.SparkOutOfMemoryError: [UNABLE_TO_ACQUIRE_MEMORY] Unable to acquire 1012 bytes of memory, got 0.",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "airplane_approx_df = GLOBAL_APPROX_SMOTENC(train_airplane, [7, 8, 9, 10, 11, 12], target='Cancelled')\n",
    "print(\"Approx Airplane Balance Score:\", balance_score(airplane_approx_df, 'Cancelled'))\n",
    "get_metrics(airplane_approx_df, test_airplane, 'Cancelled', 'Airplane Dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aa5645ca-76a4-405f-b77b-d205b77f2ba9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n",
       "\u001B[0;31mPy4JJavaError\u001B[0m                             Traceback (most recent call last)\n",
       "File \u001B[0;32m<command-1625739156208115>:1\u001B[0m\n",
       "\u001B[0;32m----> 1\u001B[0m \u001B[43mairplane_approx_df\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgroupBy\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mCancelled\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcount\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshow\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/instrumentation_utils.py:48\u001B[0m, in \u001B[0;36m_wrap_function.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n",
       "\u001B[1;32m     46\u001B[0m start \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mperf_counter()\n",
       "\u001B[1;32m     47\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
       "\u001B[0;32m---> 48\u001B[0m     res \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m     49\u001B[0m     logger\u001B[38;5;241m.\u001B[39mlog_success(\n",
       "\u001B[1;32m     50\u001B[0m         module_name, class_name, function_name, time\u001B[38;5;241m.\u001B[39mperf_counter() \u001B[38;5;241m-\u001B[39m start, signature\n",
       "\u001B[1;32m     51\u001B[0m     )\n",
       "\u001B[1;32m     52\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m res\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/sql/dataframe.py:920\u001B[0m, in \u001B[0;36mDataFrame.show\u001B[0;34m(self, n, truncate, vertical)\u001B[0m\n",
       "\u001B[1;32m    914\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m PySparkTypeError(\n",
       "\u001B[1;32m    915\u001B[0m         error_class\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNOT_A_BOOLEAN\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n",
       "\u001B[1;32m    916\u001B[0m         message_parameters\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124marg_name\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mvertical\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124marg_type\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28mtype\u001B[39m(vertical)\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m},\n",
       "\u001B[1;32m    917\u001B[0m     )\n",
       "\u001B[1;32m    919\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(truncate, \u001B[38;5;28mbool\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m truncate:\n",
       "\u001B[0;32m--> 920\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jdf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshowString\u001B[49m\u001B[43m(\u001B[49m\u001B[43mn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m20\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvertical\u001B[49m\u001B[43m)\u001B[49m)\n",
       "\u001B[1;32m    921\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
       "\u001B[1;32m    922\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1321\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n",
       "\u001B[1;32m   1315\u001B[0m command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1316\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1317\u001B[0m     args_command \u001B[38;5;241m+\u001B[39m\\\n",
       "\u001B[1;32m   1318\u001B[0m     proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n",
       "\u001B[1;32m   1320\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39msend_command(command)\n",
       "\u001B[0;32m-> 1321\u001B[0m return_value \u001B[38;5;241m=\u001B[39m \u001B[43mget_return_value\u001B[49m\u001B[43m(\u001B[49m\n",
       "\u001B[1;32m   1322\u001B[0m \u001B[43m    \u001B[49m\u001B[43manswer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgateway_client\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtarget_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m   1324\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m temp_arg \u001B[38;5;129;01min\u001B[39;00m temp_args:\n",
       "\u001B[1;32m   1325\u001B[0m     temp_arg\u001B[38;5;241m.\u001B[39m_detach()\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/pyspark/errors/exceptions.py:228\u001B[0m, in \u001B[0;36mcapture_sql_exception.<locals>.deco\u001B[0;34m(*a, **kw)\u001B[0m\n",
       "\u001B[1;32m    226\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdeco\u001B[39m(\u001B[38;5;241m*\u001B[39ma: Any, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkw: Any) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Any:\n",
       "\u001B[1;32m    227\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n",
       "\u001B[0;32m--> 228\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43ma\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkw\u001B[49m\u001B[43m)\u001B[49m\n",
       "\u001B[1;32m    229\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m Py4JJavaError \u001B[38;5;28;01mas\u001B[39;00m e:\n",
       "\u001B[1;32m    230\u001B[0m         converted \u001B[38;5;241m=\u001B[39m convert_exception(e\u001B[38;5;241m.\u001B[39mjava_exception)\n",
       "\n",
       "File \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/protocol.py:326\u001B[0m, in \u001B[0;36mget_return_value\u001B[0;34m(answer, gateway_client, target_id, name)\u001B[0m\n",
       "\u001B[1;32m    324\u001B[0m value \u001B[38;5;241m=\u001B[39m OUTPUT_CONVERTER[\u001B[38;5;28mtype\u001B[39m](answer[\u001B[38;5;241m2\u001B[39m:], gateway_client)\n",
       "\u001B[1;32m    325\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m answer[\u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m==\u001B[39m REFERENCE_TYPE:\n",
       "\u001B[0;32m--> 326\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m Py4JJavaError(\n",
       "\u001B[1;32m    327\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAn error occurred while calling \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[38;5;132;01m{2}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39m\n",
       "\u001B[1;32m    328\u001B[0m         \u001B[38;5;28mformat\u001B[39m(target_id, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m, name), value)\n",
       "\u001B[1;32m    329\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
       "\u001B[1;32m    330\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m Py4JError(\n",
       "\u001B[1;32m    331\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAn error occurred while calling \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[38;5;132;01m{2}\u001B[39;00m\u001B[38;5;124m. Trace:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{3}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39m\n",
       "\u001B[1;32m    332\u001B[0m         \u001B[38;5;28mformat\u001B[39m(target_id, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m, name, value))\n",
       "\n",
       "\u001B[0;31mPy4JJavaError\u001B[0m: An error occurred while calling o2310.showString.\n",
       ": org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 23011.0 failed 4 times, most recent failure: Lost task 0.3 in stage 23011.0 (TID 1630392) (10.139.64.12 executor 25): ExecutorLostFailure (executor 25 exited caused by one of the running tasks) Reason: Command exited with code 52\n",
       "Driver stacktrace:\n",
       "\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:3377)\n",
       "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:3309)\n",
       "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:3300)\n",
       "\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n",
       "\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n",
       "\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n",
       "\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:3300)\n",
       "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1429)\n",
       "\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1429)\n",
       "\tat scala.Option.foreach(Option.scala:407)\n",
       "\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1429)\n",
       "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3589)\n",
       "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3527)\n",
       "\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3515)\n",
       "\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:51)\n"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "arguments": {},
       "data": "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m\n\u001B[0;31mPy4JJavaError\u001B[0m                             Traceback (most recent call last)\nFile \u001B[0;32m<command-1625739156208115>:1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mairplane_approx_df\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgroupBy\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mCancelled\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcount\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshow\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\nFile \u001B[0;32m/databricks/spark/python/pyspark/instrumentation_utils.py:48\u001B[0m, in \u001B[0;36m_wrap_function.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     46\u001B[0m start \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mperf_counter()\n\u001B[1;32m     47\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 48\u001B[0m     res \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     49\u001B[0m     logger\u001B[38;5;241m.\u001B[39mlog_success(\n\u001B[1;32m     50\u001B[0m         module_name, class_name, function_name, time\u001B[38;5;241m.\u001B[39mperf_counter() \u001B[38;5;241m-\u001B[39m start, signature\n\u001B[1;32m     51\u001B[0m     )\n\u001B[1;32m     52\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m res\n\nFile \u001B[0;32m/databricks/spark/python/pyspark/sql/dataframe.py:920\u001B[0m, in \u001B[0;36mDataFrame.show\u001B[0;34m(self, n, truncate, vertical)\u001B[0m\n\u001B[1;32m    914\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m PySparkTypeError(\n\u001B[1;32m    915\u001B[0m         error_class\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNOT_A_BOOLEAN\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    916\u001B[0m         message_parameters\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124marg_name\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mvertical\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124marg_type\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28mtype\u001B[39m(vertical)\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m},\n\u001B[1;32m    917\u001B[0m     )\n\u001B[1;32m    919\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(truncate, \u001B[38;5;28mbool\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m truncate:\n\u001B[0;32m--> 920\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_jdf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshowString\u001B[49m\u001B[43m(\u001B[49m\u001B[43mn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m20\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvertical\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m    921\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    922\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\nFile \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py:1321\u001B[0m, in \u001B[0;36mJavaMember.__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m   1315\u001B[0m command \u001B[38;5;241m=\u001B[39m proto\u001B[38;5;241m.\u001B[39mCALL_COMMAND_NAME \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1316\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcommand_header \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1317\u001B[0m     args_command \u001B[38;5;241m+\u001B[39m\\\n\u001B[1;32m   1318\u001B[0m     proto\u001B[38;5;241m.\u001B[39mEND_COMMAND_PART\n\u001B[1;32m   1320\u001B[0m answer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgateway_client\u001B[38;5;241m.\u001B[39msend_command(command)\n\u001B[0;32m-> 1321\u001B[0m return_value \u001B[38;5;241m=\u001B[39m \u001B[43mget_return_value\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1322\u001B[0m \u001B[43m    \u001B[49m\u001B[43manswer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgateway_client\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtarget_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1324\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m temp_arg \u001B[38;5;129;01min\u001B[39;00m temp_args:\n\u001B[1;32m   1325\u001B[0m     temp_arg\u001B[38;5;241m.\u001B[39m_detach()\n\nFile \u001B[0;32m/databricks/spark/python/pyspark/errors/exceptions.py:228\u001B[0m, in \u001B[0;36mcapture_sql_exception.<locals>.deco\u001B[0;34m(*a, **kw)\u001B[0m\n\u001B[1;32m    226\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdeco\u001B[39m(\u001B[38;5;241m*\u001B[39ma: Any, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkw: Any) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Any:\n\u001B[1;32m    227\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 228\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43ma\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkw\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    229\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m Py4JJavaError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    230\u001B[0m         converted \u001B[38;5;241m=\u001B[39m convert_exception(e\u001B[38;5;241m.\u001B[39mjava_exception)\n\nFile \u001B[0;32m/databricks/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/protocol.py:326\u001B[0m, in \u001B[0;36mget_return_value\u001B[0;34m(answer, gateway_client, target_id, name)\u001B[0m\n\u001B[1;32m    324\u001B[0m value \u001B[38;5;241m=\u001B[39m OUTPUT_CONVERTER[\u001B[38;5;28mtype\u001B[39m](answer[\u001B[38;5;241m2\u001B[39m:], gateway_client)\n\u001B[1;32m    325\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m answer[\u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m==\u001B[39m REFERENCE_TYPE:\n\u001B[0;32m--> 326\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m Py4JJavaError(\n\u001B[1;32m    327\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAn error occurred while calling \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[38;5;132;01m{2}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39m\n\u001B[1;32m    328\u001B[0m         \u001B[38;5;28mformat\u001B[39m(target_id, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m, name), value)\n\u001B[1;32m    329\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    330\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m Py4JError(\n\u001B[1;32m    331\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAn error occurred while calling \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[38;5;132;01m{2}\u001B[39;00m\u001B[38;5;124m. Trace:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{3}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39m\n\u001B[1;32m    332\u001B[0m         \u001B[38;5;28mformat\u001B[39m(target_id, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m, name, value))\n\n\u001B[0;31mPy4JJavaError\u001B[0m: An error occurred while calling o2310.showString.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 23011.0 failed 4 times, most recent failure: Lost task 0.3 in stage 23011.0 (TID 1630392) (10.139.64.12 executor 25): ExecutorLostFailure (executor 25 exited caused by one of the running tasks) Reason: Command exited with code 52\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:3377)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:3309)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:3300)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:3300)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1429)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1429)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1429)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:3589)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3527)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:3515)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:51)\n",
       "errorSummary": "org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 23011.0 failed 4 times, most recent failure: Lost task 0.3 in stage 23011.0 (TID 1630392) (10.139.64.12 executor 25): ExecutorLostFailure (executor 25 exited caused by one of the running tasks) Reason: Command exited with code 52",
       "errorTraceType": "ansi",
       "metadata": {},
       "type": "ipynbError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "airplane_approx_df.groupBy(\"Cancelled\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dc5ba5ca-d4c7-4ce0-9b14-07e81a7b2f74",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### Exact SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c3f9ce70-4172-43ae-9263-86a9f2b9aa45",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "**Vehicle dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "05cc2686-baff-4db1-b179-1fb038a327e3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact Vehicle Balance Score: 1.0\nVehicle Dataset\n-----DecisionTree-----\nAUC 0.8323978250741588\nACC 0.8276072602942844\nRECALL BY LABEL [(0.06519654841802493, 'minority'), (0.9768974832337265, 'majority')]\nF1 0.7744834710801894\nPRECISION BY LABEL [(0.3559174178540273, 'minority'), (0.8421932884940474, 'majority')]\n-------------------------\n"
     ]
    }
   ],
   "source": [
    "vehicle_exact_df = GLOBAL_EXACT_SMOTENC(train_vehicle, [2, 3, 4, 5, 6, 7])\n",
    "print(\"Exact Vehicle Balance Score:\", balance_score(vehicle_exact_df, \"Response\"))\n",
    "get_metrics(vehicle_exact_df, test_vehicle, \"Response\", \"Vehicle Dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6b1e5890-26a0-4fa6-a2d5-2f2ab874dbe7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+\n|Response| count|\n+--------+------+\n|     0.0|223676|\n|     1.0|223676|\n+--------+------+\n\n"
     ]
    }
   ],
   "source": [
    "vehicle_exact_df.groupBy(\"Response\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4fcf8494-d72b-4ae0-9c77-662efa882a74",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "**Airplane Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6d123583-27c4-498a-b3f4-65c68f709e32",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact Airplane Balance Score: 0.4755526165407148\nAirplane Dataset\n-----DecisionTree-----\nAUC 1.0\nACC 0.9999966610572428\nRECALL BY LABEL [(1.0, 'minority'), (1.0, 'majority')]\nF1 0.9999966612009364\nPRECISION BY LABEL [(1.0, 'minority'), (1.0, 'majority')]\n-------------------------\n"
     ]
    }
   ],
   "source": [
    "airplane_exact_df = GLOBAL_EXACT_SMOTENC(train_airplane, [7, 8, 9, 10, 11, 12], target='Cancelled')\n",
    "print(\"Exact Airplane Balance Score:\", balance_score(airplane_exact_df, \"Cancelled\"))\n",
    "get_metrics(airplane_exact_df, test_airplane, 'Cancelled', 'Airplane Dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b4364119-2c26-4dc1-b415-033615d139b3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+\n|Cancelled| count|\n+---------+------+\n|      0.0|687476|\n|      1.0| 78150|\n+---------+------+\n\n"
     ]
    }
   ],
   "source": [
    "airplane_exact_df.groupBy(\"Cancelled\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3201361a-59bc-4dbc-aa5f-5987b82737c3",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### SMOTE+ENN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9feee450-5ef5-4c80-9b95-cda123269ebf",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "**Vehicle dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "97e34b43-e245-4a21-9be0-e86ab9317f68",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENN Vehicle Balance Score: 0.8590126126769618\nVehicle Dataset\n-----DecisionTree-----\nAUC 0.7988665359465111\nACC 0.8357798885312819\nRECALL BY LABEL [(0.002663257696814744, 'minority'), (0.9989152768651501, 'majority')]\nF1 0.7622734250738804\nPRECISION BY LABEL [(0.3246753246753247, 'minority'), (0.8364673310217735, 'majority')]\n-------------------------\n"
     ]
    }
   ],
   "source": [
    "vehicle_enn_df = GLOBAL_EXACT_ENN(GLOBAL_EXACT_SMOTENC(train_vehicle, [2, 3, 4, 5, 6, 7]), target_label=1.0)\n",
    "print(\"ENN Vehicle Balance Score:\", balance_score(vehicle_enn_df, \"Response\"))\n",
    "get_metrics(vehicle_enn_df, test_vehicle, \"Response\", \"Vehicle Dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1a3963eb-0bf0-4580-b875-c03e059a8b96",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+\n|Response| count|\n+--------+------+\n|     1.0| 88125|\n|     0.0|223676|\n+--------+------+\n\n"
     ]
    }
   ],
   "source": [
    "vehicle_enn_df.groupBy(\"Response\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3c02bdd3-cdd7-4aaa-af81-10e72fe0f67f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KDTree generated (EXACT_SMOTE)\nNearestNeighbors done (EXACT_SMOTE)\nSynthetic Features done (EXACT_SMOTE)\nENN-SMOTE-ENN Vehicle Balance Score: 0.9969517252810364\nVehicle Dataset\n-----DecisionTree-----\nAUC 0.8370209499358436\nACC 0.8310445676371732\nRECALL BY LABEL [(0.05206349206349206, 'minority'), (0.9849756913586701, 'majority')]\nF1 0.7724520138242079\nPRECISION BY LABEL [(0.40644361833952913, 'minority'), (0.8402126217402162, 'majority')]\n-------------------------\n"
     ]
    }
   ],
   "source": [
    "# Here we could also apply something like:\n",
    "# where we apply ENN on the majority label before SMOTE.\n",
    "\n",
    "undersampled_majority_df = GLOBAL_EXACT_ENN(train_vehicle, target_label=0.0)\n",
    "oversampled_df = GLOBAL_EXACT_SMOTENC(undersampled_majority_df, [2, 3, 4, 5, 6, 7])\n",
    "remove_noise_df = GLOBAL_EXACT_ENN(oversampled_df, target_label=1.0)\n",
    "print(\"ENN-SMOTE-ENN Vehicle Balance Score:\", balance_score(remove_noise_df, \"Response\"))\n",
    "get_metrics(remove_noise_df, test_vehicle, \"Response\", \"Vehicle Dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "22714773-545f-4823-a597-796ce3d2d767",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+\n|Response| count|\n+--------+------+\n|     1.0|181519|\n|     0.0|206750|\n+--------+------+\n\n"
     ]
    }
   ],
   "source": [
    "remove_noise_df.groupBy('Response').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d6ddf2ef-b85c-4a00-a77d-d357b8ee1bfa",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "**Airplane Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b618c92f-6611-4043-8627-7e90b1c4beb3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENN Airplane Balance Score: 0.08866852562558857\nAirplane Dataset\n-----DecisionTree-----\nAUC 0.8705225404497251\nACC 0.9951485161738387\nRECALL BY LABEL [(0.7340238764044944, 'minority'), (0.9999965975747512, 'majority')]\nF1 0.9944208031032863\nPRECISION BY LABEL [(0.9997538158542589, 'minority'), (0.9949880118662205, 'majority')]\n-------------------------\n"
     ]
    }
   ],
   "source": [
    "airplane_enn_df = GLOBAL_EXACT_ENN(GLOBAL_EXACT_SMOTENC(train_airplane, [7, 8, 9, 10, 11, 12], target='Cancelled'), target='Cancelled', target_label=1.0)\n",
    "print(\"ENN Airplane Balance Score:\", balance_score(airplane_enn_df, \"Cancelled\"))\n",
    "get_metrics(airplane_enn_df, test_airplane, \"Cancelled\", \"Airplane Dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "39ec3179-5f9b-4142-95bb-eeaf8adac710",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------+\n|Cancelled| count|\n+---------+------+\n|      1.0|  7784|\n|      0.0|687634|\n+---------+------+\n\n"
     ]
    }
   ],
   "source": [
    "airplane_enn_df.groupBy(\"Cancelled\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8f7d72eb-e8cf-4523-820d-2f28875f3548",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Testing Scalability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d429e1a3-85ef-4314-a5bf-cfcc52964ebf",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "**KDTree**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "32689029-e88b-4ded-bb9d-691081232b02",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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\n"
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "data:image/png;base64,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\n",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "image"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting a graph of KDTree performance over dataset size.\n",
    "\n",
    "\n",
    "rng = np.random.RandomState(0)\n",
    "\n",
    "times = []\n",
    "xs = []\n",
    "\n",
    "for x in range(100000, 1000000, 100000):\n",
    "\n",
    "    rs = rng.random_sample((x, 10))\n",
    "    tic = time.perf_counter()\n",
    "    tree = KDTree(rs, leaf_size=2)\n",
    "    toc = time.perf_counter()\n",
    "    times.append(toc - tic)\n",
    "    xs.append(x)\n",
    "\n",
    "plt.plot(xs, times)\n",
    "plt.title(\"Initialisation of KDTree with Varying Dataset Sizes\")\n",
    "\n",
    "plt.ylabel(\"Time (s)\")\n",
    "plt.xlabel(\"Dataset Size\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "40ada1f3-980c-4c57-bc1d-d1d828c1c8bd",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "**Local SMOTE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9ccaefb6-eafa-4f5e-a994-42a7f30d5a15",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "scalability(LOCAL_SMOTE, vehicle_scaled_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3a137a12-6729-4edd-98cb-d96a78b3e73a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "**Approx SMOTE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4f6e4af0-6354-4f7e-b572-235f09bbbf0e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "scalability(GLOBAL_APPROX_SMOTE, vehicle_scaled_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b9beb8a6-6832-479f-8a81-5a072a2ffcec",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "**Exact SMOTE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "accbb4ab-6c61-4e81-8b32-8fdc0caea803",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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\n"
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "data": "data:image/png;base64,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\n",
       "datasetInfos": [],
       "metadata": {},
       "removedWidgets": [],
       "type": "image"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "scalability(GLOBAL_EXACT_SMOTENC, smaller_scaled_airplane_df, [7, 8, 9, 10, 11, 12], 'Cancelled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "563d7128-0062-4b94-a06d-1ac3ae1922c3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KDTree generated (EXACT_SMOTE)\nNearestNeighbors done (EXACT_SMOTE)\nSynthetic Features done (EXACT_SMOTE)\nTime taken on 10,000,000 rows: 310.10\n"
     ]
    }
   ],
   "source": [
    "ss_airplane_df = scaled_airplane_df.limit(5000000)\n",
    "ss_airplane_df.cache()\n",
    "\n",
    "tic = time.perf_counter()\n",
    "GLOBAL_EXACT_SMOTENC(ss_airplane_df, [7, 8, 9, 10, 11, 12], target='Cancelled').collect()\n",
    "toc = time.perf_counter()\n",
    "\n",
    "print(\"Time taken on 5,000,000 rows: %0.2f\" % (toc - tic))"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "team12-project",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
